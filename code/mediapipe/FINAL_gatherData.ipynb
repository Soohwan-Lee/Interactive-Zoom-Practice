{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8daf622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "575f0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "# mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97698188",
   "metadata": {},
   "source": [
    "# Test Detection & Make Landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80007b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "# Initiate holistic model\n",
    "prevTime = 0\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        ###\n",
    "        initialTime = time.time()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        ### First point\n",
    "        firstTime = time.time() - initialTime\n",
    "        cv2.putText(image, f'1: {round(firstTime,3)}', (20,100), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 1)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        ### Seocnd point\n",
    "        secondTime = time.time() - initialTime\n",
    "        cv2.putText(image, f'2: {round(secondTime,3)}', (20,150), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 1)\n",
    "        \n",
    "        # Calculate FPS\n",
    "        currTime = time.time()\n",
    "        fps = 1 / (currTime - prevTime)\n",
    "        prevTime = currTime\n",
    "        cv2.putText(image, f'FPS: {round(fps,3)}', (20,40), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 1)\n",
    "        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4688728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pose_coords = len(results.pose_landmarks.landmark)\n",
    "# num_pose_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d6cdf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pose_coords = 22\n",
    "num_pose_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9edec4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"LEFT\" hand coords\n",
    "# num_left_hand_coords = len(results.right_hand_landmarks.landmark)\n",
    "num_left_hand_coords = 20\n",
    "num_left_hand_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd8680e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"RIGHT\" hand coords\n",
    "# num_right_hand_coords = len(results.left_hand_landmarks.landmark)\n",
    "num_right_hand_coords = 20\n",
    "num_right_hand_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "491fb2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hand_coords = num_right_hand_coords + num_left_hand_coords\n",
    "num_hand_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06a4ce50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pose_hand_coords = num_pose_coords + num_right_hand_coords + num_left_hand_coords\n",
    "num_pose_hand_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ae8eb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_face_coords = len(results.face_landmarks.landmark)\n",
    "num_face_coords = 467\n",
    "num_face_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9adb22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_hand_landmarks = ['class']\n",
    "# for val in range(1, num_pose_hand_coords+1):\n",
    "#     pose_hand_landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6edeb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks = ['class']\n",
    "for val in range(1, num_face_coords+1):\n",
    "    face_landmarks += ['x{}'.format(val), 'y{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e28292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_landmarks = ['class']\n",
    "# for val in range(1, num_pose_coords+1):\n",
    "#     pose_landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b241f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand_landmarks = ['class']\n",
    "# for val in range(1, num_hand_coords+1):\n",
    "#     hand_landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b35df34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_landmarks = ['class']\n",
    "for val in range(1, num_pose_coords+1):\n",
    "    pose_hand_landmarks += ['x{}'.format(val), 'y{}'.format(val)]\n",
    "for val in range(num_pose_coords+1, num_pose_coords+num_hand_coords+1):\n",
    "    pose_hand_landmarks += ['x{}'.format(val), 'y{}'.format(val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53853600",
   "metadata": {},
   "source": [
    "# Set the Directory Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "133e8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rawData = \".//rawData\"\n",
    "path_model = \".//model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c40df",
   "metadata": {},
   "source": [
    "# Pose & Hand Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a496864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## New file\n",
    "# pose_hand_file = '//211103pose_hand_sample_JY_KR.csv'\n",
    "# with open(path_rawData + pose_hand_file, mode='w', newline='') as f:\n",
    "#     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#     csv_writer.writerow(pose_hand_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7da95314",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_file = '//211102pose_hand_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2680154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b0a72591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait 3 seconds\n",
      "Recording Start!\n"
     ]
    }
   ],
   "source": [
    "### Revise one\n",
    "### Remove unnecessary value & Hand Coordinate Move\n",
    "\n",
    "start = False\n",
    "waiting = False\n",
    "checker = False\n",
    "waiting_time = time.time()\n",
    "max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image, 1)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        if start:\n",
    "            # Export coordinates\n",
    "            try:\n",
    "                # Extract Pose landmarks\n",
    "                pose = results.pose_landmarks.landmark\n",
    "                pose_row = list(np.array([[pose[i].x-pose[0].x, pose[i].y-pose[0].y] \n",
    "                                          for i in range(1, num_pose_coords+1)]).flatten())\n",
    "                try:\n",
    "                    # Extract \"RIGHT\" Hand lanmarks\n",
    "                    righthand = results.left_hand_landmarks.landmark\n",
    "                    righthand_row = list(np.array([[righthand[i].x - righthand[0].x, righthand[i].y - righthand[0].y]\n",
    "                                                   for i in range(1,num_right_hand_coords+1)]).flatten())\n",
    "                except:\n",
    "                    righthand_row = [0 for i in range(num_right_hand_coords*2)]\n",
    "\n",
    "                try:\n",
    "                    # Extract \"LEFT\" Hand lanmarks\n",
    "                    lefthand = results.right_hand_landmarks.landmark\n",
    "                    lefthand_row = list(np.array([[lefthand[i].x - lefthand[0].x, lefthand[i].y - lefthand[0].y]\n",
    "                                                  for i in range(1,num_left_hand_coords+1)]).flatten())\n",
    "                except:\n",
    "                    lefthand_row = [0 for i in range(num_left_hand_coords*2)]\n",
    "                        \n",
    "                \n",
    "                # Concate rows\n",
    "                row = pose_row + righthand_row + lefthand_row\n",
    "\n",
    "                # Append class name \n",
    "                row.insert(0, class_name)\n",
    "            \n",
    "\n",
    "                # Export to CSV\n",
    "                with open(path_rawData + pose_hand_file, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(row)\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "        cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "        # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "        if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "            print(\"Wait 3 seconds\")\n",
    "            waiting_time = time.time() + (3)\n",
    "            checker = True\n",
    "            \n",
    "        if time.time() > waiting_time and checker == True:\n",
    "            waiting = True\n",
    "            checker = False\n",
    "                \n",
    "        if waiting:\n",
    "            print(\"Recording Start!\")\n",
    "            max_time_end = time.time() + (30)\n",
    "            start = True\n",
    "            waiting = False\n",
    "        \n",
    "        # r키를 눌러서 녹화 시작 후 30초 후에 녹화 종료\n",
    "        if time.time() > max_time_end and start == True:\n",
    "            start = False\n",
    "            break\n",
    "        \n",
    "        # q키를 눌러서 강제로 녹화 종료 가능\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            start = False\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6ddbfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Revise one\n",
    "\n",
    "# start = False\n",
    "# waiting = False\n",
    "# checker = False\n",
    "# waiting_time = time.time()\n",
    "# max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3, 1280)\n",
    "# cap.set(4, 720)\n",
    "# # Initiate holistic model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor Feed\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.flip(image, 1)\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         # Make Detections\n",
    "#         results = holistic.process(image)\n",
    "#         # print(results.face_landmarks)\n",
    "        \n",
    "#         # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "#         # Recolor image back to BGR for rendering\n",
    "#         image.flags.writeable = True   \n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "#         # 2. Right hand\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 3. Left Hand\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 4. Pose Detections\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "        \n",
    "#         if start:\n",
    "#             # Export coordinates\n",
    "#             try:\n",
    "#                 # Extract Pose landmarks\n",
    "#                 pose = results.pose_landmarks.landmark\n",
    "#                 pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten()) \n",
    "                \n",
    "#                 try:\n",
    "#                     # Extract \"RIGHT\" Hand lanmarks\n",
    "#                     righthand = results.left_hand_landmarks.landmark\n",
    "#                     righthand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in righthand]).flatten())\n",
    "#                 except:\n",
    "#                     righthand_row = [0 for i in range(num_right_hand_coords*3)]\n",
    "\n",
    "#                 try:\n",
    "#                     # Extract \"LEFT\" Hand lanmarks\n",
    "#                     lefthand = results.right_hand_landmarks.landmark\n",
    "#                     lefthand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in lefthand]).flatten())\n",
    "#                 except:\n",
    "#                     lefthand_row = [0 for i in range(num_left_hand_coords*3)]\n",
    "                        \n",
    "                \n",
    "#                 # Concate rows\n",
    "#                 row = pose_row + righthand_row + lefthand_row\n",
    "\n",
    "#                 # Append class name \n",
    "#                 row.insert(0, class_name)\n",
    "            \n",
    "\n",
    "#                 # Export to CSV\n",
    "#                 with open(path_rawData + pose_hand_file, mode='a', newline='') as f:\n",
    "#                     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                     csv_writer.writerow(row)\n",
    "#             except:\n",
    "#                 pass\n",
    "                        \n",
    "#         cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "#             print(\"Wait 3 seconds\")\n",
    "#             waiting_time = time.time() + (3)\n",
    "#             checker = True\n",
    "            \n",
    "#         if time.time() > waiting_time and checker == True:\n",
    "#             waiting = True\n",
    "#             checker = False\n",
    "                \n",
    "#         if waiting:\n",
    "#             print(\"Recording Start!\")\n",
    "#             max_time_end = time.time() + (10)\n",
    "#             start = True\n",
    "#             waiting = False\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 후 30초 후에 녹화 종료\n",
    "#         if time.time() > max_time_end and start == True:\n",
    "#             start = False\n",
    "#             break\n",
    "        \n",
    "#         # q키를 눌러서 강제로 녹화 종료 가능\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             start = False\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8636b430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording Start!\n"
     ]
    }
   ],
   "source": [
    "# ### 손 하나가 안보이면 예외처리가 되는 에러\n",
    "\n",
    "# start = False\n",
    "# max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3, 1280)\n",
    "# cap.set(4, 720)\n",
    "# # Initiate holistic model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor Feed\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.flip(image, 1)\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         # Make Detections\n",
    "#         results = holistic.process(image)\n",
    "#         # print(results.face_landmarks)\n",
    "        \n",
    "#         # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "#         # Recolor image back to BGR for rendering\n",
    "#         image.flags.writeable = True   \n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "# #         # 1. Draw face landmarks\n",
    "# #         mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "# #                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "# #                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "# #                                  )\n",
    "        \n",
    "#         # 2. Right hand\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 3. Left Hand\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 4. Pose Detections\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "        \n",
    "#         if start:\n",
    "#             # Export coordinates\n",
    "#             try:\n",
    "#                 # Extract Pose landmarks\n",
    "#                 pose = results.pose_landmarks.landmark\n",
    "#                 pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "# #                 # Extract Face landmarks\n",
    "# #                 face = results.face_landmarks.landmark\n",
    "# #                 face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "                \n",
    "#                 # Extract \"RIGHT\" Hand lanmarks\n",
    "#                 righthand = results.left_hand_landmarks.landmark\n",
    "#                 righthand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in righthand]).flatten())\n",
    "                \n",
    "#                 # Extract \"LEFT\" Hand lanmarks\n",
    "#                 lefthand = results.right_hand_landmarks.landmark\n",
    "#                 lefthand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in lefthand]).flatten())\n",
    "                \n",
    "#                 # Concate rows\n",
    "#                 row = pose_row + righthand_row + lefthand_row\n",
    " \n",
    "#                 # Append class name \n",
    "#                 row.insert(0, class_name)\n",
    "                \n",
    "#                 # Export to CSV\n",
    "#                 with open('pose_hand_sample.csv', mode='a', newline='') as f:\n",
    "#                     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                     csv_writer.writerow(row)\n",
    "\n",
    "#             except:\n",
    "#                 pass\n",
    "                        \n",
    "#         cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "#             print(\"Recording Start!\")\n",
    "#             max_time_end = time.time() + (5)\n",
    "#             start = True\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 후 15초 후에 녹화 종료\n",
    "#         if time.time() > max_time_end and start == True:\n",
    "#             start = False\n",
    "#             break\n",
    "        \n",
    "#         # q키를 눌러서 강제로 녹화 종료 가능\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             start = False\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486972b",
   "metadata": {},
   "source": [
    "# Hand Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e631230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand_file = '//210910hand_sample.csv'\n",
    "# with open(path_rawData+fileName, mode='w', newline='') as f:\n",
    "#     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#     csv_writer.writerow(hand_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34a733a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_name = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bcb6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Revise one\n",
    "\n",
    "# start = False\n",
    "# waiting = False\n",
    "# checker = False\n",
    "# right = True\n",
    "# left = True\n",
    "\n",
    "# waiting_time = time.time()\n",
    "# max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3, 1280)\n",
    "# cap.set(4, 720)\n",
    "# # Initiate holistic model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor Feed\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.flip(image, 1)\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         # Make Detections\n",
    "#         results = holistic.process(image)\n",
    "#         # print(results.face_landmarks)\n",
    "        \n",
    "#         # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "#         # Recolor image back to BGR for rendering\n",
    "#         image.flags.writeable = True   \n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "#         # 2. Right hand\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 3. Left Hand\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "        \n",
    "# #         righthand = results.left_hand_landmarks.landmark\n",
    "# #         for landmark in righthand:\n",
    "# #             print(landmark)\n",
    "        \n",
    "#         if start:\n",
    "#             # Export coordinates\n",
    "#             try:\n",
    "                \n",
    "#                 try:\n",
    "#                     # Extract \"RIGHT\" Hand lanmarks\n",
    "#                     righthand = results.left_hand_landmarks.landmark\n",
    "#                     righthand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in righthand]).flatten())\n",
    "#                     right = True\n",
    "#                 except:\n",
    "#                     righthand_row = [0 for i in range(num_right_hand_coords*3)]\n",
    "#                     right = False\n",
    "\n",
    "#                 try:\n",
    "#                     # Extract \"LEFT\" Hand lanmarks\n",
    "#                     lefthand = results.right_hand_landmarks.landmark\n",
    "#                     lefthand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in lefthand]).flatten())\n",
    "#                     left = True\n",
    "#                 except:\n",
    "#                     lefthand_row = [0 for i in range(num_left_hand_coords*3)]\n",
    "#                     left = False\n",
    "                \n",
    "#                 if right != False or left != False:\n",
    "#                     # Concate rows\n",
    "#                     row = righthand_row + lefthand_row\n",
    "\n",
    "#                     # Append class name \n",
    "#                     row.insert(0, class_name)\n",
    "\n",
    "\n",
    "#                     # Export to CSV\n",
    "#                     with open(path_rawData + hand_file, mode='a', newline='') as f:\n",
    "#                         csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                         csv_writer.writerow(row)\n",
    "                        \n",
    "#             except:\n",
    "#                 pass\n",
    "                        \n",
    "#         cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "#             print(\"Wait 3 seconds\")\n",
    "#             waiting_time = time.time() + (3)\n",
    "#             checker = True\n",
    "            \n",
    "#         if time.time() > waiting_time and checker == True:\n",
    "#             waiting = True\n",
    "#             checker = False\n",
    "                \n",
    "#         if waiting:\n",
    "#             print(\"Recording Start!\")\n",
    "#             max_time_end = time.time() + (10)\n",
    "#             start = True\n",
    "#             waiting = False\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 후 30초 후에 녹화 종료\n",
    "#         if time.time() > max_time_end and start == True:\n",
    "#             start = False\n",
    "#             break\n",
    "        \n",
    "#         # q키를 눌러서 강제로 녹화 종료 가능\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             start = False\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43fb37d",
   "metadata": {},
   "source": [
    "# Face Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09777f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## New file\n",
    "# face_file = '//211103face_sample_JY_KR.csv'\n",
    "# with open(path_rawData + face_file, mode='w', newline='') as f:\n",
    "#     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#     csv_writer.writerow(face_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c0971c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_file = '//211102face_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1d4b40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a690f9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording Start!\n"
     ]
    }
   ],
   "source": [
    "start = False\n",
    "max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image, 1)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        if start:\n",
    "            # Export coordinates\n",
    "            try:\n",
    "                # Extract Face landmarks\n",
    "                face = results.face_landmarks.landmark\n",
    "#                 face_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in face]).flatten())            \n",
    "                face_row = list(np.array([[face[i].x-face[0].x, face[i].y-face[0].y] \n",
    "                                          for i in range(1, num_face_coords+1)]).flatten())\n",
    "                # Concate rows\n",
    "                row = face_row\n",
    "\n",
    "                # Append class name \n",
    "                row.insert(0, class_name)\n",
    "\n",
    "                # Export to CSV\n",
    "                with open(path_rawData + face_file, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(row)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "        cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "        # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "        if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "            print(\"Recording Start!\")\n",
    "            max_time_end = time.time() + (30)\n",
    "            start = True\n",
    "        \n",
    "        # r키를 눌러서 녹화 시작 후 15초 후에 녹화 종료\n",
    "        if time.time() > max_time_end and start == True:\n",
    "            start = False\n",
    "            break\n",
    "        \n",
    "        # q키를 눌러서 강제로 녹화 종료 가능\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            start = False\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788e1aff",
   "metadata": {},
   "source": [
    "# Read in Collected Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90f55e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Collected Data and Process\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train Machine Learning Classification Model\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Evaluate and Serialize Model\n",
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e27599de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_df = pd.read_csv(path_rawData + '//FINAL_pose_hand_sample.csv')\n",
    "face_df = pd.read_csv(path_rawData + '//FINAL_face_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba189924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN Value\n",
    "pose_hand_df = pose_hand_df.dropna(axis=0)\n",
    "face_df = face_df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "34e8a491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x58</th>\n",
       "      <th>y58</th>\n",
       "      <th>x59</th>\n",
       "      <th>y59</th>\n",
       "      <th>x60</th>\n",
       "      <th>y60</th>\n",
       "      <th>x61</th>\n",
       "      <th>y61</th>\n",
       "      <th>x62</th>\n",
       "      <th>y62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>-0.044480</td>\n",
       "      <td>0.030187</td>\n",
       "      <td>-0.042889</td>\n",
       "      <td>0.040033</td>\n",
       "      <td>-0.040399</td>\n",
       "      <td>-0.018198</td>\n",
       "      <td>-0.045264</td>\n",
       "      <td>-0.030378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>-0.042933</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>-0.041534</td>\n",
       "      <td>0.039909</td>\n",
       "      <td>-0.039268</td>\n",
       "      <td>-0.018420</td>\n",
       "      <td>-0.044005</td>\n",
       "      <td>-0.030583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016958</td>\n",
       "      <td>-0.041713</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>-0.040425</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>-0.038265</td>\n",
       "      <td>-0.018617</td>\n",
       "      <td>-0.043032</td>\n",
       "      <td>-0.030728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016951</td>\n",
       "      <td>-0.041077</td>\n",
       "      <td>0.030052</td>\n",
       "      <td>-0.039841</td>\n",
       "      <td>0.039633</td>\n",
       "      <td>-0.037771</td>\n",
       "      <td>-0.018633</td>\n",
       "      <td>-0.042519</td>\n",
       "      <td>-0.030742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>-0.040886</td>\n",
       "      <td>0.030079</td>\n",
       "      <td>-0.039684</td>\n",
       "      <td>0.039631</td>\n",
       "      <td>-0.037657</td>\n",
       "      <td>-0.018666</td>\n",
       "      <td>-0.042373</td>\n",
       "      <td>-0.030774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        x2        y2        x3        y3  \\\n",
       "0      0  0.017115 -0.044480  0.030187 -0.042889  0.040033 -0.040399   \n",
       "1      0  0.017054 -0.042933  0.030162 -0.041534  0.039909 -0.039268   \n",
       "2      0  0.016958 -0.041713  0.030030 -0.040425  0.039648 -0.038265   \n",
       "3      0  0.016951 -0.041077  0.030052 -0.039841  0.039633 -0.037771   \n",
       "4      0  0.016943 -0.040886  0.030079 -0.039684  0.039631 -0.037657   \n",
       "\n",
       "         x4        y4        x5  ...  x58  y58  x59  y59  x60  y60  x61  y61  \\\n",
       "0 -0.018198 -0.045264 -0.030378  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1 -0.018420 -0.044005 -0.030583  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2 -0.018617 -0.043032 -0.030728  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3 -0.018633 -0.042519 -0.030742  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4 -0.018666 -0.042373 -0.030774  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   x62  y62  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d7679033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x58</th>\n",
       "      <th>y58</th>\n",
       "      <th>x59</th>\n",
       "      <th>y59</th>\n",
       "      <th>x60</th>\n",
       "      <th>y60</th>\n",
       "      <th>x61</th>\n",
       "      <th>y61</th>\n",
       "      <th>x62</th>\n",
       "      <th>y62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77271</th>\n",
       "      <td>16</td>\n",
       "      <td>0.020798</td>\n",
       "      <td>-0.051449</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>-0.049637</td>\n",
       "      <td>0.045510</td>\n",
       "      <td>-0.047634</td>\n",
       "      <td>-0.017685</td>\n",
       "      <td>-0.055913</td>\n",
       "      <td>-0.031495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193182</td>\n",
       "      <td>-0.060257</td>\n",
       "      <td>-0.073272</td>\n",
       "      <td>0.051618</td>\n",
       "      <td>-0.117638</td>\n",
       "      <td>0.047839</td>\n",
       "      <td>-0.143994</td>\n",
       "      <td>0.048148</td>\n",
       "      <td>-0.168682</td>\n",
       "      <td>0.037178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77272</th>\n",
       "      <td>16</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>-0.051242</td>\n",
       "      <td>0.031786</td>\n",
       "      <td>-0.049417</td>\n",
       "      <td>0.045587</td>\n",
       "      <td>-0.047344</td>\n",
       "      <td>-0.017623</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.031443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165687</td>\n",
       "      <td>-0.114491</td>\n",
       "      <td>-0.065254</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>-0.107849</td>\n",
       "      <td>0.013595</td>\n",
       "      <td>-0.134391</td>\n",
       "      <td>-0.003104</td>\n",
       "      <td>-0.157389</td>\n",
       "      <td>-0.026795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77273</th>\n",
       "      <td>16</td>\n",
       "      <td>0.020823</td>\n",
       "      <td>-0.051316</td>\n",
       "      <td>0.031742</td>\n",
       "      <td>-0.049501</td>\n",
       "      <td>0.045605</td>\n",
       "      <td>-0.047442</td>\n",
       "      <td>-0.017717</td>\n",
       "      <td>-0.055764</td>\n",
       "      <td>-0.031563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106748</td>\n",
       "      <td>-0.066153</td>\n",
       "      <td>-0.036603</td>\n",
       "      <td>0.030814</td>\n",
       "      <td>-0.068374</td>\n",
       "      <td>0.030587</td>\n",
       "      <td>-0.088559</td>\n",
       "      <td>0.019511</td>\n",
       "      <td>-0.105481</td>\n",
       "      <td>0.002263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77274</th>\n",
       "      <td>16</td>\n",
       "      <td>0.020550</td>\n",
       "      <td>-0.051565</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>-0.049742</td>\n",
       "      <td>0.045355</td>\n",
       "      <td>-0.047672</td>\n",
       "      <td>-0.018040</td>\n",
       "      <td>-0.056012</td>\n",
       "      <td>-0.031946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050880</td>\n",
       "      <td>-0.164164</td>\n",
       "      <td>-0.038107</td>\n",
       "      <td>-0.001774</td>\n",
       "      <td>-0.048505</td>\n",
       "      <td>-0.014285</td>\n",
       "      <td>-0.052546</td>\n",
       "      <td>-0.027951</td>\n",
       "      <td>-0.055490</td>\n",
       "      <td>-0.046310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77275</th>\n",
       "      <td>16</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>-0.051532</td>\n",
       "      <td>0.031611</td>\n",
       "      <td>-0.049704</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>-0.047623</td>\n",
       "      <td>-0.017852</td>\n",
       "      <td>-0.056013</td>\n",
       "      <td>-0.031595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088270</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.027588</td>\n",
       "      <td>0.030585</td>\n",
       "      <td>0.039318</td>\n",
       "      <td>0.035390</td>\n",
       "      <td>0.051909</td>\n",
       "      <td>0.039618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class        x1        y1        x2        y2        x3        y3  \\\n",
       "77271     16  0.020798 -0.051449  0.031726 -0.049637  0.045510 -0.047634   \n",
       "77272     16  0.020862 -0.051242  0.031786 -0.049417  0.045587 -0.047344   \n",
       "77273     16  0.020823 -0.051316  0.031742 -0.049501  0.045605 -0.047442   \n",
       "77274     16  0.020550 -0.051565  0.031475 -0.049742  0.045355 -0.047672   \n",
       "77275     16  0.020620 -0.051532  0.031611 -0.049704  0.045208 -0.047623   \n",
       "\n",
       "             x4        y4        x5  ...       x58       y58       x59  \\\n",
       "77271 -0.017685 -0.055913 -0.031495  ... -0.193182 -0.060257 -0.073272   \n",
       "77272 -0.017623 -0.055767 -0.031443  ... -0.165687 -0.114491 -0.065254   \n",
       "77273 -0.017717 -0.055764 -0.031563  ... -0.106748 -0.066153 -0.036603   \n",
       "77274 -0.018040 -0.056012 -0.031946  ... -0.050880 -0.164164 -0.038107   \n",
       "77275 -0.017852 -0.056013 -0.031595  ...  0.088270  0.009117  0.011662   \n",
       "\n",
       "            y59       x60       y60       x61       y61       x62       y62  \n",
       "77271  0.051618 -0.117638  0.047839 -0.143994  0.048148 -0.168682  0.037178  \n",
       "77272  0.015701 -0.107849  0.013595 -0.134391 -0.003104 -0.157389 -0.026795  \n",
       "77273  0.030814 -0.068374  0.030587 -0.088559  0.019511 -0.105481  0.002263  \n",
       "77274 -0.001774 -0.048505 -0.014285 -0.052546 -0.027951 -0.055490 -0.046310  \n",
       "77275  0.016760  0.027588  0.030585  0.039318  0.035390  0.051909  0.039618  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8c3195e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x463</th>\n",
       "      <th>y463</th>\n",
       "      <th>x464</th>\n",
       "      <th>y464</th>\n",
       "      <th>x465</th>\n",
       "      <th>y465</th>\n",
       "      <th>x466</th>\n",
       "      <th>y466</th>\n",
       "      <th>x467</th>\n",
       "      <th>y467</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>-0.052010</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>-0.035174</td>\n",
       "      <td>-0.005677</td>\n",
       "      <td>-0.097104</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>-0.066860</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>-0.132457</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>-0.128881</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>-0.126562</td>\n",
       "      <td>0.055480</td>\n",
       "      <td>-0.142176</td>\n",
       "      <td>0.059348</td>\n",
       "      <td>-0.148753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>-0.051512</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>-0.034823</td>\n",
       "      <td>-0.005937</td>\n",
       "      <td>-0.096690</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>-0.066379</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018992</td>\n",
       "      <td>-0.131864</td>\n",
       "      <td>0.014750</td>\n",
       "      <td>-0.128349</td>\n",
       "      <td>0.012510</td>\n",
       "      <td>-0.126074</td>\n",
       "      <td>0.054355</td>\n",
       "      <td>-0.140971</td>\n",
       "      <td>0.058244</td>\n",
       "      <td>-0.147559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>-0.051704</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>-0.035036</td>\n",
       "      <td>-0.006291</td>\n",
       "      <td>-0.096848</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>-0.066542</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019190</td>\n",
       "      <td>-0.132448</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>-0.128895</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>-0.126586</td>\n",
       "      <td>0.054893</td>\n",
       "      <td>-0.142013</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>-0.148553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>-0.051985</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>-0.035017</td>\n",
       "      <td>-0.006137</td>\n",
       "      <td>-0.096837</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>-0.066821</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>-0.131324</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>-0.127876</td>\n",
       "      <td>0.012439</td>\n",
       "      <td>-0.125681</td>\n",
       "      <td>0.054632</td>\n",
       "      <td>-0.140213</td>\n",
       "      <td>0.058507</td>\n",
       "      <td>-0.146737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>-0.051550</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>-0.035091</td>\n",
       "      <td>-0.006189</td>\n",
       "      <td>-0.096762</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>-0.066341</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019268</td>\n",
       "      <td>-0.132763</td>\n",
       "      <td>0.014913</td>\n",
       "      <td>-0.129159</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>-0.126777</td>\n",
       "      <td>0.054854</td>\n",
       "      <td>-0.141952</td>\n",
       "      <td>0.058776</td>\n",
       "      <td>-0.148627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 935 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        x2        y2        x3        y3  \\\n",
       "0      0  0.001782 -0.052010  0.000543 -0.035174 -0.005677 -0.097104   \n",
       "1      0  0.001732 -0.051512  0.000466 -0.034823 -0.005937 -0.096690   \n",
       "2      0  0.001272 -0.051704  0.000305 -0.035036 -0.006291 -0.096848   \n",
       "3      0  0.001628 -0.051985  0.000364 -0.035017 -0.006137 -0.096837   \n",
       "4      0  0.001421 -0.051550  0.000318 -0.035091 -0.006189 -0.096762   \n",
       "\n",
       "         x4        y4        x5  ...      x463      y463      x464      y464  \\\n",
       "0  0.001867 -0.066860  0.001556  ...  0.019778 -0.132457  0.015420 -0.128881   \n",
       "1  0.001772 -0.066379  0.001371  ...  0.018992 -0.131864  0.014750 -0.128349   \n",
       "2  0.001265 -0.066542  0.000913  ...  0.019190 -0.132448  0.014858 -0.128895   \n",
       "3  0.001660 -0.066821  0.001246  ...  0.019014 -0.131324  0.014705 -0.127876   \n",
       "4  0.001444 -0.066341  0.001085  ...  0.019268 -0.132763  0.014913 -0.129159   \n",
       "\n",
       "       x465      y465      x466      y466      x467      y467  \n",
       "0  0.013095 -0.126562  0.055480 -0.142176  0.059348 -0.148753  \n",
       "1  0.012510 -0.126074  0.054355 -0.140971  0.058244 -0.147559  \n",
       "2  0.012536 -0.126586  0.054893 -0.142013  0.058791 -0.148553  \n",
       "3  0.012439 -0.125681  0.054632 -0.140213  0.058507 -0.146737  \n",
       "4  0.012597 -0.126777  0.054854 -0.141952  0.058776 -0.148627  \n",
       "\n",
       "[5 rows x 935 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4441961f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x463</th>\n",
       "      <th>y463</th>\n",
       "      <th>x464</th>\n",
       "      <th>y464</th>\n",
       "      <th>x465</th>\n",
       "      <th>y465</th>\n",
       "      <th>x466</th>\n",
       "      <th>y466</th>\n",
       "      <th>x467</th>\n",
       "      <th>y467</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13436</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.045954</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.033137</td>\n",
       "      <td>-0.006234</td>\n",
       "      <td>-0.095264</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.060691</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018202</td>\n",
       "      <td>-0.133833</td>\n",
       "      <td>0.014318</td>\n",
       "      <td>-0.130425</td>\n",
       "      <td>0.012208</td>\n",
       "      <td>-0.127845</td>\n",
       "      <td>0.051403</td>\n",
       "      <td>-0.138366</td>\n",
       "      <td>0.055357</td>\n",
       "      <td>-0.145912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13437</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.046965</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>-0.033804</td>\n",
       "      <td>-0.006573</td>\n",
       "      <td>-0.095875</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.061663</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017733</td>\n",
       "      <td>-0.134134</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>-0.130742</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>-0.128201</td>\n",
       "      <td>0.050838</td>\n",
       "      <td>-0.138411</td>\n",
       "      <td>0.054861</td>\n",
       "      <td>-0.146141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13438</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.046598</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>-0.033397</td>\n",
       "      <td>-0.006513</td>\n",
       "      <td>-0.096138</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>-0.061482</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018391</td>\n",
       "      <td>-0.134347</td>\n",
       "      <td>0.014427</td>\n",
       "      <td>-0.130965</td>\n",
       "      <td>0.012282</td>\n",
       "      <td>-0.128430</td>\n",
       "      <td>0.051790</td>\n",
       "      <td>-0.138786</td>\n",
       "      <td>0.055769</td>\n",
       "      <td>-0.146309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13439</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>-0.046650</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>-0.033228</td>\n",
       "      <td>-0.006888</td>\n",
       "      <td>-0.095873</td>\n",
       "      <td>-0.000703</td>\n",
       "      <td>-0.061543</td>\n",
       "      <td>-0.000750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>-0.133627</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>-0.130332</td>\n",
       "      <td>0.011289</td>\n",
       "      <td>-0.127906</td>\n",
       "      <td>0.050218</td>\n",
       "      <td>-0.138632</td>\n",
       "      <td>0.054085</td>\n",
       "      <td>-0.145913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13440</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>-0.046868</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>-0.033649</td>\n",
       "      <td>-0.006509</td>\n",
       "      <td>-0.095634</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.061611</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017741</td>\n",
       "      <td>-0.133655</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>-0.130203</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>-0.127653</td>\n",
       "      <td>0.050969</td>\n",
       "      <td>-0.138664</td>\n",
       "      <td>0.054845</td>\n",
       "      <td>-0.145976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 935 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class        x1        y1        x2        y2        x3        y3  \\\n",
       "13436      2 -0.000149 -0.045954 -0.000346 -0.033137 -0.006234 -0.095264   \n",
       "13437      2 -0.000350 -0.046965 -0.000484 -0.033804 -0.006573 -0.095875   \n",
       "13438      2 -0.000422 -0.046598 -0.000375 -0.033397 -0.006513 -0.096138   \n",
       "13439      2 -0.000658 -0.046650 -0.000568 -0.033228 -0.006888 -0.095873   \n",
       "13440      2 -0.000251 -0.046868 -0.000410 -0.033649 -0.006509 -0.095634   \n",
       "\n",
       "             x4        y4        x5  ...      x463      y463      x464  \\\n",
       "13436 -0.000061 -0.060691 -0.000042  ...  0.018202 -0.133833  0.014318   \n",
       "13437 -0.000295 -0.061663 -0.000315  ...  0.017733 -0.134134  0.013885   \n",
       "13438 -0.000394 -0.061482 -0.000348  ...  0.018391 -0.134347  0.014427   \n",
       "13439 -0.000703 -0.061543 -0.000750  ...  0.017262 -0.133627  0.013364   \n",
       "13440 -0.000220 -0.061611 -0.000256  ...  0.017741 -0.133655  0.013828   \n",
       "\n",
       "           y464      x465      y465      x466      y466      x467      y467  \n",
       "13436 -0.130425  0.012208 -0.127845  0.051403 -0.138366  0.055357 -0.145912  \n",
       "13437 -0.130742  0.011810 -0.128201  0.050838 -0.138411  0.054861 -0.146141  \n",
       "13438 -0.130965  0.012282 -0.128430  0.051790 -0.138786  0.055769 -0.146309  \n",
       "13439 -0.130332  0.011289 -0.127906  0.050218 -0.138632  0.054085 -0.145913  \n",
       "13440 -0.130203  0.011747 -0.127653  0.050969 -0.138664  0.054845 -0.145976  \n",
       "\n",
       "[5 rows x 935 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07817916",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_X = pose_hand_df.drop('class', axis=1) # features\n",
    "pose_hand_y = pose_hand_df['class'] # target value\n",
    "face_X = face_df.drop('class', axis=1) # features\n",
    "face_y = face_df['class'] # target value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dcb6dc",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351e4a71",
   "metadata": {},
   "source": [
    "### Preprocessing for Hold-out Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "acd9c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "size = 0.2\n",
    "pose_hand_X_train, pose_hand_X_test, pose_hand_y_train, pose_hand_y_test = train_test_split(pose_hand_X, pose_hand_y, stratify=pose_hand_y, test_size=size, random_state=1234)\n",
    "face_X_train, face_X_test, face_y_train, face_y_test = train_test_split(face_X, face_y, stratify=face_y, test_size=size, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ccaa55c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     4125\n",
       "6     3825\n",
       "0     3603\n",
       "1     3600\n",
       "3     3600\n",
       "12    3599\n",
       "7     3599\n",
       "16    3599\n",
       "4     3598\n",
       "14    3598\n",
       "13    3598\n",
       "2     3598\n",
       "10    3597\n",
       "11    3594\n",
       "8     3593\n",
       "9     3592\n",
       "15    3502\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3ecb1296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     1032\n",
       "6      957\n",
       "0      901\n",
       "3      900\n",
       "14     900\n",
       "13     900\n",
       "1      900\n",
       "16     900\n",
       "12     900\n",
       "7      900\n",
       "10     899\n",
       "2      899\n",
       "4      899\n",
       "11     898\n",
       "9      898\n",
       "8      898\n",
       "15     875\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "098130c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3586\n",
       "0    3586\n",
       "1    3580\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e42d336d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    897\n",
       "0    897\n",
       "1    895\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b396e",
   "metadata": {},
   "source": [
    "### Hold-out validation for pose_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3f000b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'sv':make_pipeline(StandardScaler(), SVC()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1bf033d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "pose_hand_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(pose_hand_X_train, pose_hand_y_train)\n",
    "    pose_hand_fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9f55ffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  2, 11, ...,  0, 10,  4], dtype=int64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_fit_models['sv'].predict(pose_hand_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b02b776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9992883022774327\n",
      "rc 0.9830486542443064\n",
      "rf 0.9995471014492754\n",
      "gb 0.9990942028985508\n",
      "sv 0.9988354037267081\n"
     ]
    }
   ],
   "source": [
    "# Holdout-validation for pose_hand_fit_models\n",
    "for algo, model in pose_hand_fit_models.items():\n",
    "    pred = model.predict(pose_hand_X_test)\n",
    "    print(algo, accuracy_score(pose_hand_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2475c7",
   "metadata": {},
   "source": [
    "### Hold-out validation for face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a57eb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'sv':make_pipeline(StandardScaler(), SVC()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b7f768a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "face_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(face_X_train, face_y_train)\n",
    "    face_fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "089b77ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())]),\n",
       " 'sv': Pipeline(steps=[('standardscaler', StandardScaler()), ('svc', SVC())])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9eb51f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9200446262551134\n",
      "rc 0.9308293045741911\n",
      "rf 0.9895872071402008\n",
      "gb 0.9680178505020454\n",
      "sv 0.9624395686128673\n"
     ]
    }
   ],
   "source": [
    "# Holdout-validation for face_fit_models\n",
    "for algo, model in face_fit_models.items():\n",
    "    pred = model.predict(face_X_test)\n",
    "    print(algo, accuracy_score(face_y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c80fd3",
   "metadata": {},
   "source": [
    "### Cross-validation for pose_hand & face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6549d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'sv':make_pipeline(StandardScaler(), SVC()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6379d6f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "[0.92598344 0.94849563 0.99100615 0.9984471  0.99864122]\n",
      "0.9725147074288338\n",
      "rc\n",
      "[0.95930383 0.94694274 0.99437075 1.         0.99948237]\n",
      "0.9800199378346136\n",
      "rf\n",
      "[0.95658644 0.92449046 0.97955354 0.98990618 0.96797153]\n",
      "0.9637016294216899\n",
      "gb\n",
      "[0.88114648 0.90119702 0.98104173 0.98557101 0.96480104]\n",
      "0.942751457179161\n",
      "sv\n",
      "[0.94390528 0.95088968 0.98350049 0.99890003 0.99540602]\n",
      "0.9745202988640633\n"
     ]
    }
   ],
   "source": [
    "# cross-vadliation for pose_hand_model\n",
    "from sklearn import model_selection\n",
    "for algo, pipeline in pipelines.items():\n",
    "    scores = model_selection.cross_val_score(pipeline, pose_hand_X, pose_hand_y, cv=5)\n",
    "    print(algo)\n",
    "    print(scores)\n",
    "    print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d48b9e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "[0.81442916 0.85119048 0.70796131 0.92261905 0.75669643]\n",
      "0.8105792835449538\n",
      "rc\n",
      "[0.77835627 0.72916667 0.56547619 0.84263393 0.60267857]\n",
      "0.7036623246825691\n",
      "rf\n",
      "[0.71959836 0.77008929 0.79352679 0.87946429 0.75223214]\n",
      "0.7829821727407957\n",
      "gb\n",
      "[0.74005206 0.77901786 0.73623512 0.85751488 0.73809524]\n",
      "0.7701830318404789\n",
      "sv\n",
      "[0.74488657 0.73772321 0.75483631 0.87574405 0.80729167]\n",
      "0.7840963626060315\n"
     ]
    }
   ],
   "source": [
    "# cross-validation for face_model\n",
    "from sklearn import model_selection\n",
    "for algo, pipeline in pipelines.items():\n",
    "    scores = model_selection.cross_val_score(pipeline, face_X, face_y, cv=5)\n",
    "    print(algo)\n",
    "    print(scores)\n",
    "    print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34801453",
   "metadata": {},
   "source": [
    "# Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a510dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pose_hand_fit_models\n",
    "modelName = '//211104pose_hand.pkl'\n",
    "with open(path_model + modelName, 'wb') as f:\n",
    "    pickle.dump(pose_hand_fit_models['lr'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f62248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export face_fit_models\n",
    "modelName = '//211104face.pkl'\n",
    "with open(path_model + modelName, 'wb') as f:\n",
    "    pickle.dump(face_fit_models['lr'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28541444",
   "metadata": {},
   "source": [
    "# Test DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b0b12f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### Make Code Clear ###\n",
    "#######################\n",
    "\n",
    "mp_holistic = mp.solutions.holistic  # Mediapipe Solutions\n",
    "\n",
    "pose_hand_model = \"//211104pose_hand.pkl\"\n",
    "face_model = \"//211104face.pkl\"\n",
    "\n",
    "# Load Model\n",
    "with open(path_model + pose_hand_model, 'rb') as f:\n",
    "    pose_hand_model = pickle.load(f)\n",
    "with open(path_model + face_model, 'rb') as f:\n",
    "    face_model = pickle.load(f)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "prevTime = 0\n",
    "readData = True\n",
    "\n",
    "# def sample(x,y):\n",
    "#     return x,y\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Start point: Timer for make dataframe\n",
    "        if readData:\n",
    "            beginTime = time.time()\n",
    "            readData = False\n",
    "        \n",
    "        ### Start point: Timer for Debugging\n",
    "        initialTime = time.time()\n",
    "\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image, 1)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detectionsq\n",
    "        results = holistic.process(image)\n",
    "                \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------- #\n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # --------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "        \n",
    "        # Export Pose-Hand coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[pose[i].x-pose[0].x, pose[i].y-pose[0].y] \n",
    "                          for i in range(1, num_pose_coords+1)]).flatten())\n",
    "            # Extract \"RIGHT\" Hand lanmarks\n",
    "            try:\n",
    "                righthand = results.left_hand_landmarks.landmark\n",
    "                righthand_row = list(np.array([[righthand[i].x - righthand[0].x, righthand[i].y - righthand[0].y]\n",
    "                               for i in range(1,num_right_hand_coords+1)]).flatten())\n",
    "            except:\n",
    "                righthand_row = [0 for i in range(num_right_hand_coords*2)]\n",
    "\n",
    "            # Extract \"LEFT\" Hand lanmarks\n",
    "            try:\n",
    "                lefthand = results.right_hand_landmarks.landmark\n",
    "                lefthand_row = list(np.array([[lefthand[i].x - lefthand[0].x, lefthand[i].y - lefthand[0].y]\n",
    "                                                  for i in range(1,num_left_hand_coords+1)]).flatten())\n",
    "            except:\n",
    "                lefthand_row = [0 for i in range(num_left_hand_coords*2)]\n",
    "            \n",
    "            # Concate rows\n",
    "            pose_hand_row = pose_row+righthand_row+lefthand_row\n",
    "            \n",
    "            # Make Prediction\n",
    "            pose_hand_class = pose_hand_model.predict([pose_hand_row])[0]\n",
    "            pose_hand_prob = pose_hand_model.predict_proba([pose_hand_row])[0]\n",
    "                     \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(pose_hand_class)\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(pose_hand_prob[np.argmax(pose_hand_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Export Face coordinates\n",
    "        try:\n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[face[i].x - face[0].x, face[i].y - face[0].y]\n",
    "                                                  for i in range(1,num_face_coords+1)]).flatten())\n",
    "            \n",
    "            \n",
    "            # Make Prediction\n",
    "            face_class = face_model.predict([face_row])[0]\n",
    "            face_prob = face_model.predict_proba([face_row])[0]\n",
    "#             print(face_class)\n",
    "#             print(face_prob)\n",
    "            \n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (250,0), (500, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (345,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(face_class)\n",
    "                        , (340,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (265,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(face_prob[np.argmax(face_prob)],2))\n",
    "                        , (260,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Calculate FPS\n",
    "        currTime = time.time()\n",
    "        fps = 1 / (currTime - prevTime)\n",
    "        prevTime = currTime\n",
    "        cv2.putText(image, f'FPS: {round(fps,3)}', (20,100), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 1)\n",
    "        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8e35e",
   "metadata": {},
   "source": [
    "# Virtual Cam DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "77a06de9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: './effect/sample/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-fb7753cbf928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./effect/sample/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfileType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfileList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mfileList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './effect/sample/'"
     ]
    }
   ],
   "source": [
    "# Load Pose_Hand_Images with Array Test\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "\n",
    "pose_hand_imgs = []\n",
    "path = \"./effect/sample/\"\n",
    "fileType = '.png'\n",
    "fileList = os.listdir(path)\n",
    "fileList.sort()\n",
    "print(fileList)\n",
    "for i in range(0,20):\n",
    "    imgs.append(Image.open(path+str(i)+fileType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "23441b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=200x200 at 0x2132B4DC288>"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VirtualCam DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc964e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
