{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8daf622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575f0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "# mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97698188",
   "metadata": {},
   "source": [
    "# Test Detection & Make Landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80007b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3542fd3d75f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "# Initiate holistic model\n",
    "prevTime = 0\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        ###\n",
    "        initialTime = time.time()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        ### First point\n",
    "        firstTime = time.time() - initialTime\n",
    "        cv2.putText(image, f'1: {round(firstTime,3)}', (20,100), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 1)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        ### Seocnd point\n",
    "        secondTime = time.time() - initialTime\n",
    "        cv2.putText(image, f'2: {round(secondTime,3)}', (20,150), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 1)\n",
    "        \n",
    "        # Calculate FPS\n",
    "        currTime = time.time()\n",
    "        fps = 1 / (currTime - prevTime)\n",
    "        prevTime = currTime\n",
    "        cv2.putText(image, f'FPS: {round(fps,3)}', (20,40), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 1)\n",
    "        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4688728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pose_coords = len(results.pose_landmarks.landmark)\n",
    "# num_pose_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6cdf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pose_coords = 22\n",
    "num_pose_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9edec4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"LEFT\" hand coords\n",
    "# num_left_hand_coords = len(results.right_hand_landmarks.landmark)\n",
    "num_left_hand_coords = 20\n",
    "num_left_hand_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd8680e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"RIGHT\" hand coords\n",
    "# num_right_hand_coords = len(results.left_hand_landmarks.landmark)\n",
    "num_right_hand_coords = 20\n",
    "num_right_hand_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491fb2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hand_coords = num_right_hand_coords + num_left_hand_coords\n",
    "num_hand_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a4ce50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pose_hand_coords = num_pose_coords + num_right_hand_coords + num_left_hand_coords\n",
    "num_pose_hand_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae8eb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_face_coords = len(results.face_landmarks.landmark)\n",
    "num_face_coords = 467\n",
    "num_face_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9adb22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_hand_landmarks = ['class']\n",
    "# for val in range(1, num_pose_hand_coords+1):\n",
    "#     pose_hand_landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6edeb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks = ['class']\n",
    "for val in range(1, num_face_coords+1):\n",
    "    face_landmarks += ['x{}'.format(val), 'y{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e28292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose_landmarks = ['class']\n",
    "# for val in range(1, num_pose_coords+1):\n",
    "#     pose_landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b241f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand_landmarks = ['class']\n",
    "# for val in range(1, num_hand_coords+1):\n",
    "#     hand_landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b35df34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_landmarks = ['class']\n",
    "for val in range(1, num_pose_coords+1):\n",
    "    pose_hand_landmarks += ['x{}'.format(val), 'y{}'.format(val)]\n",
    "for val in range(num_pose_coords+1, num_pose_coords+num_hand_coords+1):\n",
    "    pose_hand_landmarks += ['x{}'.format(val), 'y{}'.format(val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53853600",
   "metadata": {},
   "source": [
    "# Set the Directory Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133e8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rawData = \".//rawData\"\n",
    "path_model = \".//model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c40df",
   "metadata": {},
   "source": [
    "# Pose & Hand Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "801c9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('sample.csv', mode='w', newline='') as f:\n",
    "#     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#     csv_writer.writerow(pose_hand_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a496864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_file = '//210924pose_hand_sample.csv'\n",
    "with open(path_rawData + pose_hand_file, mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(pose_hand_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77f048a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0a72591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait 3 seconds\n",
      "Recording Start!\n"
     ]
    }
   ],
   "source": [
    "### Revise one\n",
    "### Remove unnecessary value & Hand Coordinate Move\n",
    "\n",
    "start = False\n",
    "waiting = False\n",
    "checker = False\n",
    "waiting_time = time.time()\n",
    "max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image, 1)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        if start:\n",
    "            # Export coordinates\n",
    "            try:\n",
    "                # Extract Pose landmarks\n",
    "                pose = results.pose_landmarks.landmark\n",
    "                pose_row = list(np.array([[pose[i].x-pose[0].x, pose[i].y-pose[0].y] \n",
    "                                          for i in range(1, num_pose_coords+1)]).flatten())\n",
    "                try:\n",
    "                    # Extract \"RIGHT\" Hand lanmarks\n",
    "                    righthand = results.left_hand_landmarks.landmark\n",
    "                    righthand_row = list(np.array([[righthand[i].x - righthand[0].x, righthand[i].y - righthand[0].y]\n",
    "                                                   for i in range(1,num_right_hand_coords+1)]).flatten())\n",
    "                except:\n",
    "                    righthand_row = [0 for i in range(num_right_hand_coords*2)]\n",
    "\n",
    "                try:\n",
    "                    # Extract \"LEFT\" Hand lanmarks\n",
    "                    lefthand = results.right_hand_landmarks.landmark\n",
    "                    lefthand_row = list(np.array([[lefthand[i].x - lefthand[0].x, lefthand[i].y - lefthand[0].y]\n",
    "                                                  for i in range(1,num_left_hand_coords+1)]).flatten())\n",
    "                except:\n",
    "                    lefthand_row = [0 for i in range(num_left_hand_coords*2)]\n",
    "                        \n",
    "                \n",
    "                # Concate rows\n",
    "                row = pose_row + righthand_row + lefthand_row\n",
    "\n",
    "                # Append class name \n",
    "                row.insert(0, class_name)\n",
    "            \n",
    "\n",
    "                # Export to CSV\n",
    "                with open(path_rawData + pose_hand_file, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(row)\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "        cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "        # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "        if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "            print(\"Wait 3 seconds\")\n",
    "            waiting_time = time.time() + (3)\n",
    "            checker = True\n",
    "            \n",
    "        if time.time() > waiting_time and checker == True:\n",
    "            waiting = True\n",
    "            checker = False\n",
    "                \n",
    "        if waiting:\n",
    "            print(\"Recording Start!\")\n",
    "            max_time_end = time.time() + (60)\n",
    "            start = True\n",
    "            waiting = False\n",
    "        \n",
    "        # r키를 눌러서 녹화 시작 후 30초 후에 녹화 종료\n",
    "        if time.time() > max_time_end and start == True:\n",
    "            start = False\n",
    "            break\n",
    "        \n",
    "        # q키를 눌러서 강제로 녹화 종료 가능\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            start = False\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ddbfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Revise one\n",
    "\n",
    "# start = False\n",
    "# waiting = False\n",
    "# checker = False\n",
    "# waiting_time = time.time()\n",
    "# max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3, 1280)\n",
    "# cap.set(4, 720)\n",
    "# # Initiate holistic model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor Feed\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.flip(image, 1)\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         # Make Detections\n",
    "#         results = holistic.process(image)\n",
    "#         # print(results.face_landmarks)\n",
    "        \n",
    "#         # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "#         # Recolor image back to BGR for rendering\n",
    "#         image.flags.writeable = True   \n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "#         # 2. Right hand\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 3. Left Hand\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 4. Pose Detections\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "        \n",
    "#         if start:\n",
    "#             # Export coordinates\n",
    "#             try:\n",
    "#                 # Extract Pose landmarks\n",
    "#                 pose = results.pose_landmarks.landmark\n",
    "#                 pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten()) \n",
    "                \n",
    "#                 try:\n",
    "#                     # Extract \"RIGHT\" Hand lanmarks\n",
    "#                     righthand = results.left_hand_landmarks.landmark\n",
    "#                     righthand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in righthand]).flatten())\n",
    "#                 except:\n",
    "#                     righthand_row = [0 for i in range(num_right_hand_coords*3)]\n",
    "\n",
    "#                 try:\n",
    "#                     # Extract \"LEFT\" Hand lanmarks\n",
    "#                     lefthand = results.right_hand_landmarks.landmark\n",
    "#                     lefthand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in lefthand]).flatten())\n",
    "#                 except:\n",
    "#                     lefthand_row = [0 for i in range(num_left_hand_coords*3)]\n",
    "                        \n",
    "                \n",
    "#                 # Concate rows\n",
    "#                 row = pose_row + righthand_row + lefthand_row\n",
    "\n",
    "#                 # Append class name \n",
    "#                 row.insert(0, class_name)\n",
    "            \n",
    "\n",
    "#                 # Export to CSV\n",
    "#                 with open(path_rawData + pose_hand_file, mode='a', newline='') as f:\n",
    "#                     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                     csv_writer.writerow(row)\n",
    "#             except:\n",
    "#                 pass\n",
    "                        \n",
    "#         cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "#             print(\"Wait 3 seconds\")\n",
    "#             waiting_time = time.time() + (3)\n",
    "#             checker = True\n",
    "            \n",
    "#         if time.time() > waiting_time and checker == True:\n",
    "#             waiting = True\n",
    "#             checker = False\n",
    "                \n",
    "#         if waiting:\n",
    "#             print(\"Recording Start!\")\n",
    "#             max_time_end = time.time() + (10)\n",
    "#             start = True\n",
    "#             waiting = False\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 후 30초 후에 녹화 종료\n",
    "#         if time.time() > max_time_end and start == True:\n",
    "#             start = False\n",
    "#             break\n",
    "        \n",
    "#         # q키를 눌러서 강제로 녹화 종료 가능\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             start = False\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8636b430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording Start!\n"
     ]
    }
   ],
   "source": [
    "# ### 손 하나가 안보이면 예외처리가 되는 에러\n",
    "\n",
    "# start = False\n",
    "# max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3, 1280)\n",
    "# cap.set(4, 720)\n",
    "# # Initiate holistic model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor Feed\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.flip(image, 1)\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         # Make Detections\n",
    "#         results = holistic.process(image)\n",
    "#         # print(results.face_landmarks)\n",
    "        \n",
    "#         # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "#         # Recolor image back to BGR for rendering\n",
    "#         image.flags.writeable = True   \n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "# #         # 1. Draw face landmarks\n",
    "# #         mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "# #                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "# #                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "# #                                  )\n",
    "        \n",
    "#         # 2. Right hand\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 3. Left Hand\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 4. Pose Detections\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "        \n",
    "#         if start:\n",
    "#             # Export coordinates\n",
    "#             try:\n",
    "#                 # Extract Pose landmarks\n",
    "#                 pose = results.pose_landmarks.landmark\n",
    "#                 pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "# #                 # Extract Face landmarks\n",
    "# #                 face = results.face_landmarks.landmark\n",
    "# #                 face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "                \n",
    "#                 # Extract \"RIGHT\" Hand lanmarks\n",
    "#                 righthand = results.left_hand_landmarks.landmark\n",
    "#                 righthand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in righthand]).flatten())\n",
    "                \n",
    "#                 # Extract \"LEFT\" Hand lanmarks\n",
    "#                 lefthand = results.right_hand_landmarks.landmark\n",
    "#                 lefthand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in lefthand]).flatten())\n",
    "                \n",
    "#                 # Concate rows\n",
    "#                 row = pose_row + righthand_row + lefthand_row\n",
    " \n",
    "#                 # Append class name \n",
    "#                 row.insert(0, class_name)\n",
    "                \n",
    "#                 # Export to CSV\n",
    "#                 with open('pose_hand_sample.csv', mode='a', newline='') as f:\n",
    "#                     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                     csv_writer.writerow(row)\n",
    "\n",
    "#             except:\n",
    "#                 pass\n",
    "                        \n",
    "#         cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "#             print(\"Recording Start!\")\n",
    "#             max_time_end = time.time() + (5)\n",
    "#             start = True\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 후 15초 후에 녹화 종료\n",
    "#         if time.time() > max_time_end and start == True:\n",
    "#             start = False\n",
    "#             break\n",
    "        \n",
    "#         # q키를 눌러서 강제로 녹화 종료 가능\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             start = False\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486972b",
   "metadata": {},
   "source": [
    "# Hand Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e631230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand_file = '//210910hand_sample.csv'\n",
    "# with open(path_rawData+fileName, mode='w', newline='') as f:\n",
    "#     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#     csv_writer.writerow(hand_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34a733a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_name = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bcb6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Revise one\n",
    "\n",
    "# start = False\n",
    "# waiting = False\n",
    "# checker = False\n",
    "# right = True\n",
    "# left = True\n",
    "\n",
    "# waiting_time = time.time()\n",
    "# max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3, 1280)\n",
    "# cap.set(4, 720)\n",
    "# # Initiate holistic model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor Feed\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.flip(image, 1)\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         # Make Detections\n",
    "#         results = holistic.process(image)\n",
    "#         # print(results.face_landmarks)\n",
    "        \n",
    "#         # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "#         # Recolor image back to BGR for rendering\n",
    "#         image.flags.writeable = True   \n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "#         # 2. Right hand\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 3. Left Hand\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "        \n",
    "# #         righthand = results.left_hand_landmarks.landmark\n",
    "# #         for landmark in righthand:\n",
    "# #             print(landmark)\n",
    "        \n",
    "#         if start:\n",
    "#             # Export coordinates\n",
    "#             try:\n",
    "                \n",
    "#                 try:\n",
    "#                     # Extract \"RIGHT\" Hand lanmarks\n",
    "#                     righthand = results.left_hand_landmarks.landmark\n",
    "#                     righthand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in righthand]).flatten())\n",
    "#                     right = True\n",
    "#                 except:\n",
    "#                     righthand_row = [0 for i in range(num_right_hand_coords*3)]\n",
    "#                     right = False\n",
    "\n",
    "#                 try:\n",
    "#                     # Extract \"LEFT\" Hand lanmarks\n",
    "#                     lefthand = results.right_hand_landmarks.landmark\n",
    "#                     lefthand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in lefthand]).flatten())\n",
    "#                     left = True\n",
    "#                 except:\n",
    "#                     lefthand_row = [0 for i in range(num_left_hand_coords*3)]\n",
    "#                     left = False\n",
    "                \n",
    "#                 if right != False or left != False:\n",
    "#                     # Concate rows\n",
    "#                     row = righthand_row + lefthand_row\n",
    "\n",
    "#                     # Append class name \n",
    "#                     row.insert(0, class_name)\n",
    "\n",
    "\n",
    "#                     # Export to CSV\n",
    "#                     with open(path_rawData + hand_file, mode='a', newline='') as f:\n",
    "#                         csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                         csv_writer.writerow(row)\n",
    "                        \n",
    "#             except:\n",
    "#                 pass\n",
    "                        \n",
    "#         cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "#             print(\"Wait 3 seconds\")\n",
    "#             waiting_time = time.time() + (3)\n",
    "#             checker = True\n",
    "            \n",
    "#         if time.time() > waiting_time and checker == True:\n",
    "#             waiting = True\n",
    "#             checker = False\n",
    "                \n",
    "#         if waiting:\n",
    "#             print(\"Recording Start!\")\n",
    "#             max_time_end = time.time() + (10)\n",
    "#             start = True\n",
    "#             waiting = False\n",
    "        \n",
    "#         # r키를 눌러서 녹화 시작 후 30초 후에 녹화 종료\n",
    "#         if time.time() > max_time_end and start == True:\n",
    "#             start = False\n",
    "#             break\n",
    "        \n",
    "#         # q키를 눌러서 강제로 녹화 종료 가능\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             start = False\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43fb37d",
   "metadata": {},
   "source": [
    "# Face Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09777f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_file = '//210924face_sample.csv'\n",
    "with open(path_rawData + face_file, mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(face_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d4b40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a690f9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording Start!\n"
     ]
    }
   ],
   "source": [
    "start = False\n",
    "max_time_end = time.time()\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image, 1)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        if start:\n",
    "            # Export coordinates\n",
    "            try:\n",
    "                # Extract Face landmarks\n",
    "                face = results.face_landmarks.landmark\n",
    "#                 face_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in face]).flatten())            \n",
    "                face_row = list(np.array([[face[i].x-face[0].x, face[i].y-face[0].y] \n",
    "                                          for i in range(1, num_face_coords+1)]).flatten())\n",
    "                # Concate rows\n",
    "                row = face_row\n",
    "\n",
    "                # Append class name \n",
    "                row.insert(0, class_name)\n",
    "\n",
    "                # Export to CSV\n",
    "                with open(path_rawData + face_file, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(row)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "        cv2.imshow('Gather Pose Data', image)\n",
    "        \n",
    "        # r키를 눌러서 녹화 시작 - 20초간 녹화\n",
    "        if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "            print(\"Recording Start!\")\n",
    "            max_time_end = time.time() + (60)\n",
    "            start = True\n",
    "        \n",
    "        # r키를 눌러서 녹화 시작 후 15초 후에 녹화 종료\n",
    "        if time.time() > max_time_end and start == True:\n",
    "            start = False\n",
    "            break\n",
    "        \n",
    "        # q키를 눌러서 강제로 녹화 종료 가능\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            start = False\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513683a5",
   "metadata": {},
   "source": [
    "# Train Custom Model Using Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44192c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Collected Data and Process\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train Machine Learning Classification Model\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Evaluate and Serialize Model\n",
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788e1aff",
   "metadata": {},
   "source": [
    "### Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e27599de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_df = pd.read_csv(path_rawData + '//210924pose_hand_sample.csv')\n",
    "face_df = pd.read_csv(path_rawData + '//210924face_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba189924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN Value\n",
    "pose_hand_df = pose_hand_df.dropna(axis=0)\n",
    "face_df = face_df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e8a491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x58</th>\n",
       "      <th>y58</th>\n",
       "      <th>x59</th>\n",
       "      <th>y59</th>\n",
       "      <th>x60</th>\n",
       "      <th>y60</th>\n",
       "      <th>x61</th>\n",
       "      <th>y61</th>\n",
       "      <th>x62</th>\n",
       "      <th>y62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019812</td>\n",
       "      <td>-0.063104</td>\n",
       "      <td>0.035576</td>\n",
       "      <td>-0.062442</td>\n",
       "      <td>0.050231</td>\n",
       "      <td>-0.060305</td>\n",
       "      <td>-0.021937</td>\n",
       "      <td>-0.061169</td>\n",
       "      <td>-0.035918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>-0.063723</td>\n",
       "      <td>0.035594</td>\n",
       "      <td>-0.063116</td>\n",
       "      <td>0.050285</td>\n",
       "      <td>-0.060637</td>\n",
       "      <td>-0.021898</td>\n",
       "      <td>-0.061875</td>\n",
       "      <td>-0.035902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>-0.064764</td>\n",
       "      <td>0.035725</td>\n",
       "      <td>-0.064167</td>\n",
       "      <td>0.050436</td>\n",
       "      <td>-0.061187</td>\n",
       "      <td>-0.021760</td>\n",
       "      <td>-0.063101</td>\n",
       "      <td>-0.035791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>-0.064930</td>\n",
       "      <td>0.035659</td>\n",
       "      <td>-0.064442</td>\n",
       "      <td>0.050380</td>\n",
       "      <td>-0.061287</td>\n",
       "      <td>-0.021343</td>\n",
       "      <td>-0.063491</td>\n",
       "      <td>-0.035294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>-0.064781</td>\n",
       "      <td>0.035402</td>\n",
       "      <td>-0.064376</td>\n",
       "      <td>0.050114</td>\n",
       "      <td>-0.061243</td>\n",
       "      <td>-0.020775</td>\n",
       "      <td>-0.063433</td>\n",
       "      <td>-0.034403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        x2        y2        x3        y3  \\\n",
       "0      0  0.019812 -0.063104  0.035576 -0.062442  0.050231 -0.060305   \n",
       "1      0  0.019855 -0.063723  0.035594 -0.063116  0.050285 -0.060637   \n",
       "2      0  0.019995 -0.064764  0.035725 -0.064167  0.050436 -0.061187   \n",
       "3      0  0.019988 -0.064930  0.035659 -0.064442  0.050380 -0.061287   \n",
       "4      0  0.019845 -0.064781  0.035402 -0.064376  0.050114 -0.061243   \n",
       "\n",
       "         x4        y4        x5  ...  x58  y58  x59  y59  x60  y60  x61  y61  \\\n",
       "0 -0.021937 -0.061169 -0.035918  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1 -0.021898 -0.061875 -0.035902  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2 -0.021760 -0.063101 -0.035791  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3 -0.021343 -0.063491 -0.035294  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4 -0.020775 -0.063433 -0.034403  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   x62  y62  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7679033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x58</th>\n",
       "      <th>y58</th>\n",
       "      <th>x59</th>\n",
       "      <th>y59</th>\n",
       "      <th>x60</th>\n",
       "      <th>y60</th>\n",
       "      <th>x61</th>\n",
       "      <th>y61</th>\n",
       "      <th>x62</th>\n",
       "      <th>y62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15268</th>\n",
       "      <td>11</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>-0.061510</td>\n",
       "      <td>0.032502</td>\n",
       "      <td>-0.064011</td>\n",
       "      <td>0.044534</td>\n",
       "      <td>-0.065752</td>\n",
       "      <td>-0.020796</td>\n",
       "      <td>-0.053363</td>\n",
       "      <td>-0.033789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>-0.224254</td>\n",
       "      <td>0.065822</td>\n",
       "      <td>-0.038500</td>\n",
       "      <td>0.055940</td>\n",
       "      <td>-0.107973</td>\n",
       "      <td>0.040980</td>\n",
       "      <td>-0.147547</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>-0.177257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15269</th>\n",
       "      <td>11</td>\n",
       "      <td>0.017785</td>\n",
       "      <td>-0.061528</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>-0.064029</td>\n",
       "      <td>0.043164</td>\n",
       "      <td>-0.065744</td>\n",
       "      <td>-0.021500</td>\n",
       "      <td>-0.053580</td>\n",
       "      <td>-0.034603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043631</td>\n",
       "      <td>-0.203592</td>\n",
       "      <td>0.073613</td>\n",
       "      <td>-0.012335</td>\n",
       "      <td>0.079273</td>\n",
       "      <td>-0.068517</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>-0.111684</td>\n",
       "      <td>0.047856</td>\n",
       "      <td>-0.146468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15270</th>\n",
       "      <td>11</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>-0.062569</td>\n",
       "      <td>0.031580</td>\n",
       "      <td>-0.065391</td>\n",
       "      <td>0.042650</td>\n",
       "      <td>-0.066876</td>\n",
       "      <td>-0.021532</td>\n",
       "      <td>-0.052729</td>\n",
       "      <td>-0.034263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058924</td>\n",
       "      <td>-0.201230</td>\n",
       "      <td>0.072506</td>\n",
       "      <td>-0.019923</td>\n",
       "      <td>0.079837</td>\n",
       "      <td>-0.079139</td>\n",
       "      <td>0.069358</td>\n",
       "      <td>-0.121710</td>\n",
       "      <td>0.053101</td>\n",
       "      <td>-0.154170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15271</th>\n",
       "      <td>11</td>\n",
       "      <td>0.017616</td>\n",
       "      <td>-0.063097</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>-0.065611</td>\n",
       "      <td>0.042450</td>\n",
       "      <td>-0.066895</td>\n",
       "      <td>-0.021539</td>\n",
       "      <td>-0.054013</td>\n",
       "      <td>-0.034651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035584</td>\n",
       "      <td>-0.253156</td>\n",
       "      <td>0.061763</td>\n",
       "      <td>-0.078552</td>\n",
       "      <td>0.060616</td>\n",
       "      <td>-0.149090</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>-0.190148</td>\n",
       "      <td>0.029732</td>\n",
       "      <td>-0.220743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15272</th>\n",
       "      <td>11</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>-0.063248</td>\n",
       "      <td>0.031826</td>\n",
       "      <td>-0.065902</td>\n",
       "      <td>0.042429</td>\n",
       "      <td>-0.067087</td>\n",
       "      <td>-0.021659</td>\n",
       "      <td>-0.053560</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017518</td>\n",
       "      <td>-0.200557</td>\n",
       "      <td>0.029183</td>\n",
       "      <td>-0.039451</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>-0.094069</td>\n",
       "      <td>-0.009112</td>\n",
       "      <td>-0.123191</td>\n",
       "      <td>-0.022574</td>\n",
       "      <td>-0.152166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class        x1        y1        x2        y2        x3        y3  \\\n",
       "15268     11  0.018200 -0.061510  0.032502 -0.064011  0.044534 -0.065752   \n",
       "15269     11  0.017785 -0.061528  0.032183 -0.064029  0.043164 -0.065744   \n",
       "15270     11  0.017290 -0.062569  0.031580 -0.065391  0.042650 -0.066876   \n",
       "15271     11  0.017616 -0.063097  0.031944 -0.065611  0.042450 -0.066895   \n",
       "15272     11  0.017479 -0.063248  0.031826 -0.065902  0.042429 -0.067087   \n",
       "\n",
       "             x4        y4        x5  ...       x58       y58       x59  \\\n",
       "15268 -0.020796 -0.053363 -0.033789  ...  0.023555 -0.224254  0.065822   \n",
       "15269 -0.021500 -0.053580 -0.034603  ...  0.043631 -0.203592  0.073613   \n",
       "15270 -0.021532 -0.052729 -0.034263  ...  0.058924 -0.201230  0.072506   \n",
       "15271 -0.021539 -0.054013 -0.034651  ...  0.035584 -0.253156  0.061763   \n",
       "15272 -0.021659 -0.053560 -0.034821  ... -0.017518 -0.200557  0.029183   \n",
       "\n",
       "            y59       x60       y60       x61       y61       x62       y62  \n",
       "15268 -0.038500  0.055940 -0.107973  0.040980 -0.147547  0.023755 -0.177257  \n",
       "15269 -0.012335  0.079273 -0.068517  0.066413 -0.111684  0.047856 -0.146468  \n",
       "15270 -0.019923  0.079837 -0.079139  0.069358 -0.121710  0.053101 -0.154170  \n",
       "15271 -0.078552  0.060616 -0.149090  0.047382 -0.190148  0.029732 -0.220743  \n",
       "15272 -0.039451  0.008331 -0.094069 -0.009112 -0.123191 -0.022574 -0.152166  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8c3195e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x463</th>\n",
       "      <th>y463</th>\n",
       "      <th>x464</th>\n",
       "      <th>y464</th>\n",
       "      <th>x465</th>\n",
       "      <th>y465</th>\n",
       "      <th>x466</th>\n",
       "      <th>y466</th>\n",
       "      <th>x467</th>\n",
       "      <th>y467</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001114</td>\n",
       "      <td>-0.036185</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.024166</td>\n",
       "      <td>-0.005943</td>\n",
       "      <td>-0.081120</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>-0.049960</td>\n",
       "      <td>-0.000607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>-0.114496</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>-0.111385</td>\n",
       "      <td>0.014322</td>\n",
       "      <td>-0.109231</td>\n",
       "      <td>0.055287</td>\n",
       "      <td>-0.120328</td>\n",
       "      <td>0.059143</td>\n",
       "      <td>-0.124905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001286</td>\n",
       "      <td>-0.037593</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.025362</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.082033</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>-0.051266</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021443</td>\n",
       "      <td>-0.115045</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>-0.111933</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>-0.109778</td>\n",
       "      <td>0.055266</td>\n",
       "      <td>-0.120652</td>\n",
       "      <td>0.059097</td>\n",
       "      <td>-0.125219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001255</td>\n",
       "      <td>-0.037593</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.025283</td>\n",
       "      <td>-0.006189</td>\n",
       "      <td>-0.082004</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>-0.051293</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021132</td>\n",
       "      <td>-0.115252</td>\n",
       "      <td>0.016624</td>\n",
       "      <td>-0.112070</td>\n",
       "      <td>0.014004</td>\n",
       "      <td>-0.109900</td>\n",
       "      <td>0.054844</td>\n",
       "      <td>-0.121038</td>\n",
       "      <td>0.058668</td>\n",
       "      <td>-0.125621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001434</td>\n",
       "      <td>-0.037102</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.024867</td>\n",
       "      <td>-0.006471</td>\n",
       "      <td>-0.081305</td>\n",
       "      <td>-0.001526</td>\n",
       "      <td>-0.050782</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>-0.114822</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>-0.111633</td>\n",
       "      <td>0.013808</td>\n",
       "      <td>-0.109455</td>\n",
       "      <td>0.054819</td>\n",
       "      <td>-0.120913</td>\n",
       "      <td>0.058719</td>\n",
       "      <td>-0.126054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001354</td>\n",
       "      <td>-0.037601</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.025190</td>\n",
       "      <td>-0.006522</td>\n",
       "      <td>-0.081453</td>\n",
       "      <td>-0.001460</td>\n",
       "      <td>-0.051246</td>\n",
       "      <td>-0.001118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>-0.114779</td>\n",
       "      <td>0.016430</td>\n",
       "      <td>-0.111579</td>\n",
       "      <td>0.013759</td>\n",
       "      <td>-0.109405</td>\n",
       "      <td>0.054718</td>\n",
       "      <td>-0.121107</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>-0.126335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 935 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        x2        y2        x3        y3  \\\n",
       "0      0 -0.001114 -0.036185 -0.000124 -0.024166 -0.005943 -0.081120   \n",
       "1      0 -0.001286 -0.037593 -0.000235 -0.025362 -0.006108 -0.082033   \n",
       "2      0 -0.001255 -0.037593 -0.000215 -0.025283 -0.006189 -0.082004   \n",
       "3      0 -0.001434 -0.037102 -0.000282 -0.024867 -0.006471 -0.081305   \n",
       "4      0 -0.001354 -0.037601 -0.000232 -0.025190 -0.006522 -0.081453   \n",
       "\n",
       "         x4        y4        x5  ...      x463      y463      x464      y464  \\\n",
       "0 -0.001083 -0.049960 -0.000607  ...  0.021472 -0.114496  0.016949 -0.111385   \n",
       "1 -0.001277 -0.051266 -0.000791  ...  0.021443 -0.115045  0.016901 -0.111933   \n",
       "2 -0.001279 -0.051293 -0.000848  ...  0.021132 -0.115252  0.016624 -0.112070   \n",
       "3 -0.001526 -0.050782 -0.001139  ...  0.021008 -0.114822  0.016477 -0.111633   \n",
       "4 -0.001460 -0.051246 -0.001118  ...  0.020954 -0.114779  0.016430 -0.111579   \n",
       "\n",
       "       x465      y465      x466      y466      x467      y467  \n",
       "0  0.014322 -0.109231  0.055287 -0.120328  0.059143 -0.124905  \n",
       "1  0.014256 -0.109778  0.055266 -0.120652  0.059097 -0.125219  \n",
       "2  0.014004 -0.109900  0.054844 -0.121038  0.058668 -0.125621  \n",
       "3  0.013808 -0.109455  0.054819 -0.120913  0.058719 -0.126054  \n",
       "4  0.013759 -0.109405  0.054718 -0.121107  0.058606 -0.126335  \n",
       "\n",
       "[5 rows x 935 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4441961f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x463</th>\n",
       "      <th>y463</th>\n",
       "      <th>x464</th>\n",
       "      <th>y464</th>\n",
       "      <th>x465</th>\n",
       "      <th>y465</th>\n",
       "      <th>x466</th>\n",
       "      <th>y466</th>\n",
       "      <th>x467</th>\n",
       "      <th>y467</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.002081</td>\n",
       "      <td>-0.047608</td>\n",
       "      <td>-0.001014</td>\n",
       "      <td>-0.032307</td>\n",
       "      <td>-0.007470</td>\n",
       "      <td>-0.090632</td>\n",
       "      <td>-0.002233</td>\n",
       "      <td>-0.061626</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018958</td>\n",
       "      <td>-0.123100</td>\n",
       "      <td>0.014690</td>\n",
       "      <td>-0.119525</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>-0.117374</td>\n",
       "      <td>0.052437</td>\n",
       "      <td>-0.130289</td>\n",
       "      <td>0.056172</td>\n",
       "      <td>-0.136281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.001769</td>\n",
       "      <td>-0.047872</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-0.032280</td>\n",
       "      <td>-0.007076</td>\n",
       "      <td>-0.090696</td>\n",
       "      <td>-0.001888</td>\n",
       "      <td>-0.061896</td>\n",
       "      <td>-0.001649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018943</td>\n",
       "      <td>-0.122022</td>\n",
       "      <td>0.014738</td>\n",
       "      <td>-0.118693</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>-0.116730</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>-0.128653</td>\n",
       "      <td>0.055839</td>\n",
       "      <td>-0.134578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.047162</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>-0.032089</td>\n",
       "      <td>-0.007276</td>\n",
       "      <td>-0.090279</td>\n",
       "      <td>-0.002094</td>\n",
       "      <td>-0.061139</td>\n",
       "      <td>-0.001871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>-0.122625</td>\n",
       "      <td>0.014609</td>\n",
       "      <td>-0.119163</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>-0.117059</td>\n",
       "      <td>0.052111</td>\n",
       "      <td>-0.129709</td>\n",
       "      <td>0.055851</td>\n",
       "      <td>-0.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.001862</td>\n",
       "      <td>-0.047322</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>-0.032288</td>\n",
       "      <td>-0.007154</td>\n",
       "      <td>-0.090674</td>\n",
       "      <td>-0.001981</td>\n",
       "      <td>-0.061307</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018709</td>\n",
       "      <td>-0.123053</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>-0.119621</td>\n",
       "      <td>0.012099</td>\n",
       "      <td>-0.117526</td>\n",
       "      <td>0.051808</td>\n",
       "      <td>-0.129947</td>\n",
       "      <td>0.055517</td>\n",
       "      <td>-0.135750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.001635</td>\n",
       "      <td>-0.047526</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-0.032519</td>\n",
       "      <td>-0.006980</td>\n",
       "      <td>-0.090966</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>-0.061486</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>-0.124512</td>\n",
       "      <td>0.014812</td>\n",
       "      <td>-0.120828</td>\n",
       "      <td>0.012380</td>\n",
       "      <td>-0.118562</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>-0.132419</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>-0.138297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 935 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class        x1        y1        x2        y2        x3        y3  \\\n",
       "2648      2 -0.002081 -0.047608 -0.001014 -0.032307 -0.007470 -0.090632   \n",
       "2649      2 -0.001769 -0.047872 -0.000838 -0.032280 -0.007076 -0.090696   \n",
       "2650      2 -0.001956 -0.047162 -0.000924 -0.032089 -0.007276 -0.090279   \n",
       "2651      2 -0.001862 -0.047322 -0.000891 -0.032288 -0.007154 -0.090674   \n",
       "2652      2 -0.001635 -0.047526 -0.000701 -0.032519 -0.006980 -0.090966   \n",
       "\n",
       "            x4        y4        x5  ...      x463      y463      x464  \\\n",
       "2648 -0.002233 -0.061626 -0.002009  ...  0.018958 -0.123100  0.014690   \n",
       "2649 -0.001888 -0.061896 -0.001649  ...  0.018943 -0.122022  0.014738   \n",
       "2650 -0.002094 -0.061139 -0.001871  ...  0.018824 -0.122625  0.014609   \n",
       "2651 -0.001981 -0.061307 -0.001751  ...  0.018709 -0.123053  0.014531   \n",
       "2652 -0.001758 -0.061486 -0.001516  ...  0.019012 -0.124512  0.014812   \n",
       "\n",
       "          y464      x465      y465      x466      y466      x467      y467  \n",
       "2648 -0.119525  0.012170 -0.117374  0.052437 -0.130289  0.056172 -0.136281  \n",
       "2649 -0.118693  0.012269 -0.116730  0.052083 -0.128653  0.055839 -0.134578  \n",
       "2650 -0.119163  0.012136 -0.117059  0.052111 -0.129709  0.055851 -0.135643  \n",
       "2651 -0.119621  0.012099 -0.117526  0.051808 -0.129947  0.055517 -0.135750  \n",
       "2652 -0.120828  0.012380 -0.118562  0.052387 -0.132419  0.056108 -0.138297  \n",
       "\n",
       "[5 rows x 935 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07817916",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_X = pose_hand_df.drop('class', axis=1) # features\n",
    "pose_hand_y = pose_hand_df['class'] # target value\n",
    "face_X = face_df.drop('class', axis=1) # features\n",
    "face_y = face_df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acd9c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_X_train, pose_hand_X_test, pose_hand_y_train, pose_hand_y_test = train_test_split(pose_hand_X, pose_hand_y, stratify=pose_hand_y, test_size=0.25, random_state=1234)\n",
    "face_X_train, face_X_test, face_y_train, face_y_test = train_test_split(face_X, face_y, stratify=face_y, test_size=0.25, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccaa55c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     1348\n",
       "3     1348\n",
       "1     1347\n",
       "2     1347\n",
       "11    1345\n",
       "4      675\n",
       "7      675\n",
       "0      675\n",
       "6      674\n",
       "10     674\n",
       "5      673\n",
       "8      673\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ecb1296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     450\n",
       "9     450\n",
       "2     449\n",
       "1     449\n",
       "11    448\n",
       "10    225\n",
       "5     225\n",
       "4     225\n",
       "0     225\n",
       "7     225\n",
       "6     224\n",
       "8     224\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "098130c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    670\n",
       "0    670\n",
       "2    649\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e42d336d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    224\n",
       "0    223\n",
       "2    217\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b396e",
   "metadata": {},
   "source": [
    "### Train Machine Learning Classificaiton Model for pose_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f000b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'sv':make_pipeline(StandardScaler(), SVC()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bf033d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "pose_hand_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(pose_hand_X_train, pose_hand_y_train)\n",
    "    pose_hand_fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb74ee88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pose_hand_fit_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c5048efdb0bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpose_hand_fit_models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pose_hand_fit_models' is not defined"
     ]
    }
   ],
   "source": [
    "pose_hand_fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f55ffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 11, 10, ...,  4,  1,  9], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_hand_fit_models['sv'].predict(pose_hand_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b02b776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9994763026970411\n",
      "rc 0.99528672427337\n",
      "rf 1.0\n",
      "gb 0.9984289080911233\n",
      "sv 0.9997381513485205\n"
     ]
    }
   ],
   "source": [
    "# Test for pose_hand_fit_models\n",
    "for algo, model in pose_hand_fit_models.items():\n",
    "    pred = model.predict(pose_hand_X_test)\n",
    "    print(algo, accuracy_score(pose_hand_y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fca80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pose_hand_fit_models\n",
    "modelName = '//210924pose_hand.pkl'\n",
    "with open(path_model + modelName, 'wb') as f:\n",
    "    pickle.dump(pose_hand_fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2475c7",
   "metadata": {},
   "source": [
    "### Train Machine Learning Classificaiton Model for face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57eb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'sv':make_pipeline(StandardScaler(), SVC()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7f768a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "face_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(face_X_train, face_y_train)\n",
    "    face_fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "089b77ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())]),\n",
       " 'sv': Pipeline(steps=[('standardscaler', StandardScaler()), ('svc', SVC())])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9eb51f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9849397590361446\n",
      "rc 0.9819277108433735\n",
      "rf 0.9789156626506024\n",
      "gb 0.9804216867469879\n",
      "sv 0.9804216867469879\n"
     ]
    }
   ],
   "source": [
    "# Test for face_fit_models\n",
    "for algo, model in face_fit_models.items():\n",
    "    pred = model.predict(face_X_test)\n",
    "    print(algo, accuracy_score(face_y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae4363c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pose_hand_fit_models\n",
    "modelName = '//210924face.pkl'\n",
    "with open(path_model + modelName, 'wb') as f:\n",
    "    pickle.dump(face_fit_models['lr'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88481e",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6549d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'sv':make_pipeline(StandardScaler(), SVC()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc099b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_hand_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(face_X_train, face_y_train)\n",
    "    face_fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f489c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for face_fit_models\n",
    "for algo, model in face_fit_models.items():\n",
    "    pred = model.predict(face_X_test)\n",
    "    print(algo, accuracy_score(face_y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2473d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12218\n",
      "3055\n",
      "12218\n",
      "3055\n",
      "12218\n",
      "3055\n",
      "12219\n",
      "3054\n",
      "12219\n",
      "3054\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5).split(pose_hand_X, pose_hand_y)\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    X_train=pose_hand_X.iloc[train]\n",
    "    y_train=pose_hand_y.iloc[train]\n",
    "    X_test=pose_hand_X.iloc[test]\n",
    "    y_test=pose_hand_y.iloc[test]\n",
    "    print(len(train))\n",
    "    print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "55567d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression())])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드:  1, 클래스 분포: [ 810 1616 1616 1619  810  808  808  810  807 1618  810 1613], 정확도: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드:  2, 클래스 분포: [ 810 1616 1616 1619  810  808  808  810  807 1619  809 1613], 정확도: 0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드:  3, 클래스 분포: [ 810 1616 1617 1618  810  808  808  810  807 1619  809 1613], 정확도: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드:  4, 클래스 분포: [ 810 1616 1617 1618  810  808  808  810  808 1618  809 1614], 정확도: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드:  5, 클래스 분포: [ 810 1616 1617 1618  810  808  808  810  808 1618  809 1614], 정확도: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드:  6, 클래스 분포: [ 810 1616 1617 1618  810  808  808  810  808 1618  809 1614], 정확도: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드:  7, 클래스 분포: [ 810 1617 1616 1618  810  808  809  810  807 1618  809 1614], 정확도: 0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드:  8, 클래스 분포: [ 810 1617 1616 1618  810  808  809  810  807 1618  809 1614], 정확도: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드:  9, 클래스 분포: [ 810 1617 1616 1618  810  809  808  810  807 1618  809 1614], 정확도: 0.990\n",
      "폴드: 10, 클래스 분포: [ 810 1617 1616 1618  810  809  808  810  807 1618  809 1614], 정확도: 1.000\n",
      "\n",
      "CV 정확도: 0.994 +/- 0.005\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('ridgeclassifier', RidgeClassifier())])\n",
      "\n",
      "CV 정확도: 0.994 +/- 0.005\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestclassifier', RandomForestClassifier())])\n",
      "\n",
      "CV 정확도: 0.994 +/- 0.005\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingclassifier', GradientBoostingClassifier())])\n",
      "\n",
      "CV 정확도: 0.994 +/- 0.005\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()), ('svc', SVC())])\n",
      "\n",
      "CV 정확도: 0.994 +/- 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeSooHwan\\anaconda3\\envs\\zoom\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# cross-vadlidation for pose_hand_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10).split(pose_hand_X, pose_hand_y)\n",
    "\n",
    "scores = []\n",
    "for algo, pipeline in pipelines.items():\n",
    "    print(pipeline)\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        pipeline.fit(pose_hand_X.iloc[train], pose_hand_y.iloc[train])\n",
    "        score = pipeline.score(pose_hand_X.iloc[test], pose_hand_y.iloc[test])\n",
    "        scores.append(score)\n",
    "        print('Fold: %2d, Class Distribution: %s, Accuracy: %.3f' % (k+1, np.bincount(pose_hand_y.iloc[train]), score))\n",
    "    print('\\nCV Accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369aa0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28541444",
   "metadata": {},
   "source": [
    "# Test DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b12f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### Make Code Clear ###\n",
    "#######################\n",
    "\n",
    "mp_holistic = mp.solutions.holistic  # Mediapipe Solutions\n",
    "\n",
    "pose_hand_model = \"//210924pose_hand.pkl\"\n",
    "face_model = \"//210924face.pkl\"\n",
    "\n",
    "# Load Model\n",
    "with open(path_model + pose_hand_model, 'rb') as f:\n",
    "    pose_hand_model = pickle.load(f)\n",
    "with open(path_model + face_model, 'rb') as f:\n",
    "    face_model = pickle.load(f)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "prevTime = 0\n",
    "readData = True\n",
    "\n",
    "# def sample(x,y):\n",
    "#     return x,y\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Start point: Timer for make dataframe\n",
    "        if readData:\n",
    "            beginTime = time.time()\n",
    "            readData = False\n",
    "        \n",
    "        ### Start point: Timer for Debugging\n",
    "        initialTime = time.time()\n",
    "\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image, 1)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detectionsq\n",
    "        results = holistic.process(image)\n",
    "                \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # --------------------------------------------------------------------------------------------- #\n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # --------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "        \n",
    "        # Export Pose-Hand coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[pose[i].x-pose[0].x, pose[i].y-pose[0].y] \n",
    "                          for i in range(1, num_pose_coords+1)]).flatten())\n",
    "            # Extract \"RIGHT\" Hand lanmarks\n",
    "            try:\n",
    "                righthand = results.left_hand_landmarks.landmark\n",
    "                righthand_row = list(np.array([[righthand[i].x - righthand[0].x, righthand[i].y - righthand[0].y]\n",
    "                               for i in range(1,num_right_hand_coords+1)]).flatten())\n",
    "            except:\n",
    "                righthand_row = [0 for i in range(num_right_hand_coords*2)]\n",
    "\n",
    "            # Extract \"LEFT\" Hand lanmarks\n",
    "            try:\n",
    "                lefthand = results.right_hand_landmarks.landmark\n",
    "                lefthand_row = list(np.array([[lefthand[i].x - lefthand[0].x, lefthand[i].y - lefthand[0].y]\n",
    "                                                  for i in range(1,num_left_hand_coords+1)]).flatten())\n",
    "            except:\n",
    "                lefthand_row = [0 for i in range(num_left_hand_coords*2)]\n",
    "            \n",
    "            # Concate rows\n",
    "            pose_hand_row = pose_row+righthand_row+lefthand_row\n",
    "            \n",
    "            # Make Prediction\n",
    "            pose_hand_class = pose_hand_model.predict([pose_hand_row])[0]\n",
    "            pose_hand_prob = pose_hand_model.predict_proba([pose_hand_row])[0]\n",
    "                     \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(pose_hand_class)\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(pose_hand_prob[np.argmax(pose_hand_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Export Face coordinates\n",
    "        try:\n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[face[i].x - face[0].x, face[i].y - face[0].y]\n",
    "                                                  for i in range(1,num_face_coords+1)]).flatten())\n",
    "            \n",
    "            \n",
    "            # Make Prediction\n",
    "            face_class = face_model.predict([face_row])[0]\n",
    "            face_prob = face_model.predict_proba([face_row])[0]\n",
    "            \n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (250,0), (500, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (345,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, face_class.split(' ')[0]\n",
    "                        , (340,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (265,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(face_prob[np.argmax(face_prob)],2))\n",
    "                        , (260,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Calculate FPS\n",
    "        currTime = time.time()\n",
    "        fps = 1 / (currTime - prevTime)\n",
    "        prevTime = currTime\n",
    "        cv2.putText(image, f'FPS: {round(fps,3)}', (20,100), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255), 1)\n",
    "        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8e35e",
   "metadata": {},
   "source": [
    "# Virtual Cam DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "77a06de9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: './effect/sample/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-fb7753cbf928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./effect/sample/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfileType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfileList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mfileList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './effect/sample/'"
     ]
    }
   ],
   "source": [
    "# Load Pose_Hand_Images with Array Test\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "\n",
    "pose_hand_imgs = []\n",
    "path = \"./effect/sample/\"\n",
    "fileType = '.png'\n",
    "fileList = os.listdir(path)\n",
    "fileList.sort()\n",
    "print(fileList)\n",
    "for i in range(0,20):\n",
    "    imgs.append(Image.open(path+str(i)+fileType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "23441b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=200x200 at 0x2132B4DC288>"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VirtualCam DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc964e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
